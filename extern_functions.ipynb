{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External functions for Fundus of the Eye detecting\n",
    "Makes the main application clear for user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image processing and general libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import functools\n",
    "from IPython.display import Markdown, clear_output, display, HTML\n",
    "from ipywidgets import widgets, Layout,Label, HBox, VBox, Box\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.filters import gaussian, threshold_li, sato\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage.color import rgb2hsv,rgb2gray\n",
    "import skimage.morphology as mp\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numba import jit, cuda \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, make_scorer, recall_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions for displaying and loading pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_picture(image, title=None, file=None):\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    sub = fig.add_subplot(111)\n",
    "    if title is not None:\n",
    "        sub.set_title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image) \n",
    "    if file is not None:\n",
    "        plt.savefig(file)\n",
    "\n",
    "def display_results(image_array,titles_array, file=\"img/image-results/test.jpg\"):\n",
    "    count = len(image_array)\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=count, figsize=(30,6))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        plt.sca(ax)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images_array[i])\n",
    "        plt.title(titles_array[i])\n",
    "\n",
    "    plt.savefig(file)\n",
    "    plt.show()\n",
    "    \n",
    "def display_statistics_plot(expect,mask,tpr,fpr,roc_auc,file=\"img/image-results/stats/stat-test.jpg\"):\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    title = \"Classifications metrics\"\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    original = fig.add_subplot(131)\n",
    "    original.set_title('Expert mask')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(expect)\n",
    "\n",
    "    roc_curve = fig.add_subplot(132)\n",
    "    roc_curve.set_title('Receiver Operating Characteristic')\n",
    "    roc_curve.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    roc_curve.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    xlim=[0.0, 1.0]\n",
    "    ylim=[0.0, 1.05]\n",
    "    roc_curve.set_xlim(xlim)\n",
    "    roc_curve.set_ylim(ylim)\n",
    "    roc_curve.set_xlabel('False Positive Rate')\n",
    "    roc_curve.set_ylabel('True Positive Rate')\n",
    "\n",
    "    actual = fig.add_subplot(133)\n",
    "    actual.set_title('Obtained mask')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mask)\n",
    "    \n",
    "    plt.savefig(file)\n",
    "    plt.show()\n",
    "\n",
    "def draw_roc_curve(tpr,fpr,roc_auc,title=\"Receiver Operating Characteristic\"):\n",
    "    plt.title(title)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "def display_label_distribution(y_train,y_test):\n",
    "    classes_number = 2\n",
    "    fig, ax = plt.subplots()\n",
    "    training_counts = [None] * classes_number \n",
    "    testing_counts = [None] * classes_number\n",
    "    for i in range(classes_number):\n",
    "        training_counts[i] = len(y_train[y_train == i])\n",
    "        testing_counts[i] = len(y_test[y_test == i])\n",
    "\n",
    "    train_bar = plt.bar(np.arange(classes_number)-0.2, training_counts, align='center', color = 'pink', alpha=0.75, width = 0.41, label='Training')\n",
    "    test_bar = plt.bar(np.arange(classes_number)+0.2, testing_counts, align='center', color = 'teal', alpha=0.75, width = 0.41, label = 'Testing')\n",
    "   \n",
    "    ax.set_xlabel('Labels')\n",
    "    x_ticks_labels = ['Background','Vessel']\n",
    "    ax.set_xticks((0,1))\n",
    "    ax.set_xticklabels(x_ticks_labels,rotation='horizontal', fontsize=14)\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.title('Label distribution in the training and test set')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), handles=[train_bar, test_bar], loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def get_input_model_params():\n",
    "    bootstrap=bootstrap_input.value\n",
    "    n_estimators=n_estimators_input.value\n",
    "    criterion=criterion_input.value\n",
    "    max_depth=max_depth_input.value\n",
    "    max_features=max_features_input.value\n",
    "    min_samples_leaf=min_samples_leaf_input.value\n",
    "    min_samples_split=min_samples_split_input.value\n",
    "    return bootstrap,n_estimators,criterion,max_depth,max_features,min_samples_leaf,min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pic_on_pic(img1,img2):\n",
    "    img2=img_as_float(rgb2gray(img2))\n",
    "    h = img1.shape[0]\n",
    "    w = img2.shape[1]\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            img1[y, x] = 255 if img2[y, x] > 0 else img1[y,x]\n",
    "\n",
    "    return img1\n",
    "\n",
    "def calculate_statistics(result_masks, expected_array, filename=\"test\"):\n",
    "    accuracy_list=[]\n",
    "    sensitivity_list=[]\n",
    "    precision_list=[]\n",
    "    specificity_list=[]\n",
    "    fpr_list=[]\n",
    "    f_score_list=[]\n",
    "    g_mean_list=[]\n",
    "    \n",
    "    for i,(mask, expect) in enumerate(zip(result_masks, expected_array)):\n",
    "        mask_copy, expect_copy = binarize_images(mask.copy(),expect.copy())\n",
    "        mask_array = mask_copy.flatten()\n",
    "        expect_array = expect_copy.flatten()\n",
    "        \n",
    "        true_negative, false_positive, false_negative, true_positive = confusion_matrix(mask_array, expect_array, labels=[0,1]).ravel()\n",
    "        fpr, tpr, _ = roc_curve(expect_array, mask_array)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        accuracy =  (true_positive + true_negative) / (true_positive+true_negative+false_positive+false_negative)#trafnosc\n",
    "        sensitivity =  true_positive / (true_positive + false_negative)#czulosc : tp / (tp + fn)\n",
    "        precision = true_positive / (true_positive + false_positive) # tp / tp + fp\n",
    "        specificity = true_negative / (true_negative + false_positive) #swoistosc: tn / (tn + fp)\n",
    "        f_score = 2 * precision * sensitivity /  ( precision + sensitivity)\n",
    "        g_mean = np.sqrt(sensitivity*specificity)\n",
    "        \n",
    "        accuracy_list.append(accuracy)\n",
    "        sensitivity_list.append(sensitivity)\n",
    "        precision_list.append(precision)\n",
    "        specificity_list.append(specificity)\n",
    "        f_score_list.append(f_score) \n",
    "        g_mean_list.append(g_mean)\n",
    "        \n",
    "        filepath=\"img/image-results/stats/stat-img\"+filename+str(i)+\".jpg\"\n",
    "        display_statistics_plot(expect,mask,tpr,fpr,roc_auc,filepath)\n",
    "        \n",
    "    return accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list\n",
    "\n",
    "def binarize_images(mask,expect,value=[1,1,1],thresh=0):\n",
    "    black=[0,0,0]\n",
    "    h = expect.shape[0]\n",
    "    w = expect.shape[1]\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            expect_vessel = expect[y,x]\n",
    "            detect_vessel = mask[y,x]\n",
    "            if np.amax(expect_vessel) > thresh:\n",
    "                expect[y,x]=value\n",
    "                if np.amax(detect_vessel) >thresh:\n",
    "                    mask[y,x]=value\n",
    "                else:\n",
    "                    mask[y,x]=black\n",
    "            else:\n",
    "                expect[y,x]=black\n",
    "                if np.amax(detect_vessel) > thresh:\n",
    "                    mask[y,x]=value\n",
    "                else:\n",
    "                    mask[y,x]=black\n",
    "    return mask,expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for uploading images for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageReader:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._images_array = []\n",
    "        self._expected_array = []\n",
    "        self._official_mask=[]\n",
    "\n",
    "    def load_image(self,path,file):\n",
    "        if('.jpg' in file or '.png' or '.tif' in file):\n",
    "            full_file = path+file\n",
    "            img = cv2.imread(full_file)\n",
    "            return img\n",
    "    \n",
    "    def upload_single_image(self, filename):\n",
    "        path = 'img/'\n",
    "        self._images_array.clear()\n",
    "        img = self.load_image(path,filename)\n",
    "        \n",
    "        self._images_array.append(img)\n",
    "        \n",
    "        expected_path = 'img/expected/'\n",
    "        self._expected_array.clear()\n",
    "        expected = self.load_image(expected_path,filename)\n",
    "        self._expected_array.append(expected)\n",
    "        \n",
    "        self._official_mask.clear()\n",
    "        mask_path = 'img/mask/'\n",
    "        filename = '01_h_mask.tif'\n",
    "        self._official_mask.append(self.load_image(mask_path,filename))\n",
    "\n",
    "    \n",
    "    def upload_many_images(self, path):\n",
    "        self._images_array.clear()\n",
    "        \n",
    "        expected_path = path+'expected/'\n",
    "        self._expected_array.clear()\n",
    "        \n",
    "        files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        for i,file in enumerate(files):\n",
    "            img = self.load_image(path,file)\n",
    "            \n",
    "            self._images_array.append(img)\n",
    "            \n",
    "            exp = self.load_image(expected_path,file)\n",
    "            self._expected_array.append(exp)\n",
    "        \n",
    "        self._official_mask.clear()\n",
    "        mask_path = 'img/mask/'\n",
    "        filename = '01_h_mask.tif'\n",
    "        self._official_mask.append(self.load_image(mask_path,filename))\n",
    "        print(f'Updated {i+1} files!')\n",
    "\n",
    "    def get_images_array(self):\n",
    "        return self._images_array\n",
    "    \n",
    "    def get_expected_array(self):\n",
    "        return self._expected_array\n",
    "    \n",
    "    def get_official_mask(self):\n",
    "        return self._official_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for manual fundus detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \n",
    "    def __init__(self, imageReader):\n",
    "        self._images_array = imageReader.get_images_array()\n",
    "        self._expected_array = imageReader.get_expected_array()\n",
    "        self._official_mask = imageReader.get_official_mask()\n",
    "        \n",
    "        self._result_masks = []\n",
    "        self._image_progresses = []\n",
    "        self._result_images = []\n",
    "    \n",
    "    def whole_image_processing(self):\n",
    "        self.find_fundus()\n",
    "        self.count_statistics()\n",
    "    \n",
    "    def find_fundus(self):\n",
    "        if len(self._images_array)==0:\n",
    "            display (Markdown('<span style=\"color: #ff0000\">Upload image first!</span>'))\n",
    "            return\n",
    "    \n",
    "        for i,img in enumerate(self._images_array):\n",
    "            img_orig = img.copy()\n",
    "            img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            initial = self.initial_processing(img)\n",
    "            edges = self.edge_detecting(initial)\n",
    "            detections_mask = self.vessels_mask_creating(edges)\n",
    "            final_fundus = self.fundus_final_processing(detections_mask)\n",
    "\n",
    "            final_fundus = cv2.cvtColor(final_fundus, cv2.COLOR_BGR2RGB)\n",
    "            self._result_masks.append(final_fundus)\n",
    "\n",
    "            detection_on_orygin = apply_pic_on_pic(img_orig.copy(),final_fundus)\n",
    "            self._result_images.append(detection_on_orygin)\n",
    "\n",
    "            image_progress=[img_orig,initial,final_fundus,detection_on_orygin]\n",
    "            self._image_progresses.append(image_progress)\n",
    "            \n",
    "            titles=['Original picture','Initial processing','Fundus mask','Applied on original']\n",
    "            filepath=\"img/image-results/img\"+str(i)+\".jpg\"\n",
    "            display_results(image_progress, titles,filepath)\n",
    "            \n",
    "            for i,(result,applied) in enumerate(zip(self._result_masks,self._result_images)):\n",
    "                display_picture(result,\"img/image-results/manual-masks/img\"+str(i)+\".jpg\")\n",
    "                display_picture(applied,\"img/image-results/manual-applied-\"+str(i)+\".jpg\")\n",
    "    \n",
    "    def initial_processing(self, img):\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        cl = clahe.apply(l)\n",
    "        merged = cv2.merge((cl,a,b))\n",
    "        clahed_image = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "        clahed_image[:, :, 0] = 0\n",
    "        clahed_image[:, :, 2] = 0\n",
    "        img=img_as_float(rgb2gray(clahed_image))\n",
    "        img=gaussian(img,sigma=3) \n",
    "        img=img**0.2\n",
    "\n",
    "        mask=img_as_float(rgb2gray(self._official_mask[0]))\n",
    "        img=img*mask\n",
    "\n",
    "        return img\n",
    "\n",
    "    def edge_detecting(self,img):\n",
    "        img=sato(img)\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "        img=mp.dilation(img,selem=mp.disk(6))\n",
    "        img=gaussian(img,sigma=3) \n",
    "        img=mp.closing(img, selem=mp.disk(8))\n",
    "        img=mp.erosion(img,selem=mp.disk(2))\n",
    "\n",
    "        thresh = threshold_li(img, tolerance=0.0005)\n",
    "        img = img > thresh\n",
    "\n",
    "        mask=img_as_float(rgb2gray(self._official_mask[0]))\n",
    "        mask=mp.erosion(mask, selem=mp.disk(5))\n",
    "        img=img*mask\n",
    "\n",
    "        return img\n",
    "\n",
    "    def vessels_mask_creating(self,img):\n",
    "        detection = np.zeros((img.shape[0], img.shape[1], 3), np.uint8)\n",
    "\n",
    "        for y in range(img.shape[0]):\n",
    "            for x in range(img.shape[1]):\n",
    "                if cv2.countNonZero(img[y, x]) > 0:\n",
    "                    detection[y, x] = np.array([255, 255, 255], np.uint8)\n",
    "\n",
    "        return detection\n",
    "\n",
    "    def fundus_final_processing(self,img):\n",
    "        img = np.array(img)\n",
    "        img = 255*(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 5).astype('uint8')\n",
    "\n",
    "        img=mp.erosion(img,selem=mp.disk(1))\n",
    "        img=mp.closing(img, selem=mp.disk(15))\n",
    "        img = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        return img\n",
    "\n",
    "    def get_statistics(self):\n",
    "        accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list = calculate_statistics(self._result_masks, self._expected_array,\"manual\")\n",
    "        table = pd.DataFrame({\"Accuracy\": accuracy_list,\"Sensitivity\": sensitivity_list,\"Specificity\": specificity_list, \"Geometric mean\":g_mean_list,\"Precision\": precision_list,\"Recall\":sensitivity_list,\"F1\":f_score_list})\n",
    "        display(table)\n",
    "        \n",
    "    def get_images_array(self):\n",
    "        return self._images_array\n",
    "    \n",
    "    def get_expected_array(self):\n",
    "        return self._expected_array\n",
    "    \n",
    "    def get_official_mask(self):\n",
    "        return self._official_mask\n",
    "    \n",
    "    def get_result_masks(self):\n",
    "        return self._result_masks\n",
    "    \n",
    "    def get_result_images(self):\n",
    "        return self._result_images\n",
    "    \n",
    "    def get_image_progresses(self):\n",
    "        return self._image_progresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class for classificator's fundus detecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    \n",
    "    def __init__(self, imageReader):\n",
    "        self._images_array = imageReader.get_images_array()\n",
    "        self._expected_array = imageReader.get_expected_array()\n",
    "        self._official_mask = imageReader.get_official_mask()\n",
    "        self._ImageProcessor = ImageProcessor(imageReader)\n",
    "        \n",
    "        self._model = None\n",
    "        self._X, self._y = self.read_set_from_file()\n",
    "        self._result_masks = []\n",
    "        self._result_images = []\n",
    "    \n",
    "    def whole_fundus_finding_process(self):\n",
    "        block_size = block_size_input.value\n",
    "        self.create_data_set(block_size)\n",
    "        self.train_model()\n",
    "        self.find_fundus()\n",
    "        self.get_statistics()\n",
    "        \n",
    "    def create_data_set(self, block_size):\n",
    "        expected = self._expected_array[0]\n",
    "        img = self._images_array[0]\n",
    "        img = self._ImageProcessor.initial_processing(img)   \n",
    "        \n",
    "        parts,decisions = self.split_image(img,expected,block_size)\n",
    "\n",
    "        data=[]\n",
    "        for part,decision in zip(parts,decisions):\n",
    "            one_part,_ = self.image_features_extract(part,decision)\n",
    "            data.append(one_part)\n",
    "        data_set = pd.DataFrame(data)\n",
    "        print('Image based data frame:')\n",
    "        display(data_set.head())\n",
    "        data_set.to_csv('data/model_data.csv')\n",
    "        \n",
    "        return data_set\n",
    "    \n",
    "    def split_image(self,img,expect, block_size):\n",
    "        windows=[]\n",
    "        decisions = []\n",
    "        for r in range(0,img.shape[0] - block_size, block_size):\n",
    "            for c in range(0,img.shape[0] - block_size, block_size):\n",
    "                window = img[r:r+block_size,c:c+block_size]\n",
    "                exp_window = expect[r:r+block_size,c:c+block_size]\n",
    "                center = np.amax(exp_window[exp_window.shape[0]//2,exp_window.shape[1]//2])\n",
    "                if center>50:\n",
    "                    center=1\n",
    "                else:\n",
    "                    center=0\n",
    "                decisions.append(center)\n",
    "                windows.append(window)\n",
    "\n",
    "        return windows,decisions\n",
    "            \n",
    "    def image_features_extract(self, img, decision=None): \n",
    "        data={}\n",
    "        data['variance'] = np.var(img)\n",
    "        img = img_as_ubyte(rgb2gray(img))\n",
    "        moments = cv2.moments(img)\n",
    "        data={**data,**moments}\n",
    "        hu_moments = cv2.HuMoments(moments)\n",
    "        for i,hu in enumerate(hu_moments):\n",
    "            name = \"hu\"+str(i)\n",
    "            data[name]=hu[0]\n",
    "        data['decision']=decision\n",
    "        data_for_pic = [np.var(img),moments,hu_moments]\n",
    "        return data, data_for_pic\n",
    "\n",
    "    \n",
    "    def read_set_from_file(self):\n",
    "        if isfile('data/model_data.csv'):\n",
    "            data_set = pd.read_csv('data/model_data.csv')\n",
    "            data_set=data_set.drop(\"Unnamed: 0\",axis=1)\n",
    "\n",
    "            X = data_set.iloc[:, :-1].values\n",
    "            y = data_set.iloc[:, -1].values\n",
    "        else:\n",
    "            display (Markdown('<span style=\"color: #ff0000\">No image-data csv file</span>'))\n",
    "            return\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "    def find_RandomizedSearchCV_best_params(self):\n",
    "        # Number of trees in random forest\n",
    "        n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "        max_features = ['auto', 'sqrt']\n",
    "        max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "        max_depth.append(None)\n",
    "        min_samples_split = [2, 5, 10]   # Minimum number of samples required to split a node\n",
    "        min_samples_leaf = [1, 2, 4]     # Minimum number of samples required at each leaf node\n",
    "        bootstrap = [True, False]        # Method of selecting samples for training each tree\n",
    "\n",
    "        random_grid = {'n_estimators': n_estimators,\n",
    "                       'max_features': max_features,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'bootstrap': bootstrap }\n",
    "\n",
    "        print(\"Using the random grid to search for best parameters\")\n",
    "        print(\"Random Grid options: \\n\")\n",
    "        pprint(random_grid)\n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "        # n_iter controls the number of different combinations to try\n",
    "        # cv is the number of folds to use for cross validation\n",
    "\n",
    "        X = self._X\n",
    "        y = self._y\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y)\n",
    "\n",
    "        rf_random.fit(X_train, y_train)\n",
    "        best_random = rf_random.best_estimator_\n",
    "\n",
    "        print(\"\\nRandom best params:\")\n",
    "        pprint(rf_random.best_params_)\n",
    "\n",
    "\n",
    "    def find_GridSearchCV_best_params(self):\n",
    "        param_grid = {\n",
    "            'bootstrap': [True],\n",
    "            'max_depth': [1, 10, 20, 30],\n",
    "            'max_features': [2, 3],\n",
    "            'min_samples_leaf': [3, 4, 5],\n",
    "            'min_samples_split': [2, 8, 12],\n",
    "            'n_estimators': [100, 200, 400, 800]\n",
    "        }  #grid parameters based on RandomizedSearchCV best params\n",
    "\n",
    "        rf = RandomForestClassifier()\n",
    "        grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                                  cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "        X = self._X\n",
    "        y = self._y\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y)\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_grid = grid_search.best_estimator_\n",
    "\n",
    "        print(\"\\nGrid best params:\")\n",
    "        pprint(grid_search.best_params_)\n",
    "\n",
    "      \n",
    "    @jit\n",
    "    def train_model(self,use_custom=False):\n",
    "        X = self._X\n",
    "        y = self._y\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y)\n",
    "        display_label_distribution(y_train,y_test)\n",
    "\n",
    "        if use_custom==True:\n",
    "            bootstrap,n_estimators,criterion,max_depth,max_features,min_samples_leaf,min_samples_split = get_input_model_params()\n",
    "            rf_clf = RandomForestClassifier(bootstrap=bootstrap,n_estimators=n_estimators,criterion=criterion,max_depth=max_depth,max_features=max_features,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split)\n",
    "        else:\n",
    "            rf_clf = RandomForestClassifier(bootstrap=True,criterion='gini', \n",
    "                                            max_depth=30, max_features=3,\n",
    "                                            max_leaf_nodes=None, max_samples=None,\n",
    "                                            min_samples_leaf=4, min_samples_split=2,\n",
    "                                            n_estimators=100, n_jobs=None)\n",
    "\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        rf_predictions = rf_clf.predict(X_train)\n",
    "        rf_probs = rf_clf.predict_proba(X_train)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_train,rf_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        print(classification_report(y_train, rf_predictions, labels=[0,1]))\n",
    "        draw_roc_curve(tpr,fpr,roc_auc,'Receiver Operating Characteristic - train set')\n",
    "\n",
    "        rf_predictions = rf_clf.predict(X_test)\n",
    "        rf_probs = rf_clf.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test,rf_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        print(classification_report(y_test, rf_predictions, labels=[0,1]))\n",
    "        draw_roc_curve(tpr,fpr,roc_auc,'Receiver Operating Characteristic - test set')\n",
    "\n",
    "        self._model = rf_clf\n",
    "    \n",
    "    def find_fundus(self):\n",
    "        for img in self._images_array:\n",
    "            img = self._ImageProcessor.initial_processing(img)\n",
    "\n",
    "            drawing_range={}\n",
    "            drawing_range[\"x_start\"]=0\n",
    "            drawing_range[\"x_end\"]=img.shape[0]\n",
    "            drawing_range[\"y_start\"]=0\n",
    "            drawing_range[\"y_end\"]=img.shape[1]\n",
    "            result_mask = self.vessels_mask_creating(img,drawing_range)\n",
    "            self._result_masks.append(result_mask)\n",
    "        \n",
    "        for i,result in enumerate(self._result_masks):\n",
    "            display_picture(result,\"img/image-results/model-masks/img\"+str(i)+\".jpg\")\n",
    "        \n",
    "    @jit\n",
    "    def vessels_mask_creating(self, img, drawing_range):\n",
    "        block_size = block_size_input.value//2\n",
    "        detection = np.zeros((img.shape[0], img.shape[1], 3), np.uint8)\n",
    "        decisions=[]\n",
    "\n",
    "        ###SPLITING IMAGE DRAWING INTO PARTS SO WON'T HAVE TO WAIT DAYS TO SEE RESULT\n",
    "        x_start_point = drawing_range[\"x_start\"]\n",
    "        x_end_point = drawing_range[\"x_end\"]\n",
    "        y_start_point = drawing_range[\"y_start\"]\n",
    "        y_end_point = drawing_range[\"y_end\"]\n",
    "\n",
    "        print(x_end_point)\n",
    "        maks_y = y_end_point-block_size-1\n",
    "\n",
    "        for x in range(x_start_point + block_size, x_end_point - block_size):\n",
    "            for y in range(y_start_point + block_size, y_end_point - block_size):\n",
    "                window = img[x-block_size:x+block_size,y-block_size:y+block_size]\n",
    "\n",
    "                _ ,data_set = self.image_features_extract(window)\n",
    "                data_set = [[data_set[0]],list(data_set[1].values()),[item for sublist in data_set[2] for item in sublist]]\n",
    "                data_set = [item for sublist in data_set for item in sublist]\n",
    "                decision = self._model.predict([data_set])\n",
    "                decisions.append(decision)\n",
    "                if y == maks_y:\n",
    "                    print(x,y)\n",
    "                if decision!=0:\n",
    "                    detection[x, y] = np.array([255, 255, 255], np.uint8)\n",
    "        display_picture(detection)\n",
    "        return detection   \n",
    "    \n",
    "    def get_statistics(self):\n",
    "        accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list = calculate_statistics(self._result_masks, self._expected_array,\"model\")\n",
    "        table = pd.DataFrame({\"Accuracy\": accuracy_list,\"Sensitivity\": sensitivity_list,\"Specificity\": specificity_list, \"Geometric mean\":g_mean_list,\"Precision\": precision_list,\"Recall\":sensitivity_list,\"F1\":f_score_list})\n",
    "        display(table)\n",
    "        \n",
    "    def get_images_array(self):\n",
    "        return self._images_array\n",
    "    \n",
    "    def get_expected_array(self):\n",
    "        return self._expected_array\n",
    "    \n",
    "    def get_official_mask(self):\n",
    "        return self._official_mask\n",
    "    \n",
    "    def get_result_masks(self):\n",
    "        return self._result_masks\n",
    "    \n",
    "    def get_result_images(self):\n",
    "        return self._result_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On-click functions to handle interactions with the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_upload_clicked(x):\n",
    "    clear_output()\n",
    "    display(choose_image_box)\n",
    "    imageReader.upload_single_image(filename_input.value)\n",
    "    \n",
    "    for img in imageReader.get_images_array():\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        display_picture(img)\n",
    "\n",
    "def on_update_clicked(x):\n",
    "    filepath = filename_input.value\n",
    "    imageReader.upload_single_image(filepath)\n",
    "    print(\"Updated!\")\n",
    "    \n",
    "def on_upload_many_clicked(x):\n",
    "    clear_output()\n",
    "    display(choose_image_box)\n",
    "    \n",
    "    path = filepath_input.value\n",
    "    imageReader.upload_many_images(path)\n",
    "\n",
    "def on_find_fundus_clicked(x):\n",
    "    imageProcessor.find_fundus()\n",
    "\n",
    "def on_check_stats_clicked(x, if_manual):\n",
    "    if if_manual:\n",
    "        result_masks = imageProcessor.get_result_masks()\n",
    "        expected_array = imageProcessor.get_expected_array()\n",
    "    else:\n",
    "        result_masks = imageClassifier.get_result_masks()\n",
    "        expected_array = imageClassifier.get_expected_array()\n",
    "    accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list = calculate_statistics(result_masks, expected_array)\n",
    "    \n",
    "    print(\"Accuracy is inappropriate for imbalanced classification because a high accuracy is achievable by a no skill model that only predicts the majority class.\")\n",
    "    \n",
    "    print(\"Metrics that may be useful for imbalanced classification because they focus on one class are: sensitivity-specificity and precision-recall.\")\n",
    "    print(\"Sensitivity (recall) is  how well the positive class was predicted.\")\n",
    "    print('Specificity is  how well the negative class was predicted.')\n",
    "    print('Sensitivity and specificity can be combined into a single score that balances both concerns, called the geometric mean.')\n",
    "    \n",
    "    print('Precision summarizes the fraction of examples assigned the positive class that belong to the positive class.')\n",
    "    print(\"Precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score.\")\n",
    "    \n",
    "    table = pd.DataFrame({\"Accuracy\": accuracy_list,\"Sensitivity\": sensitivity_list,\"Specificity\": specificity_list, \"Geometric mean\":g_mean_list,\"Precision\": precision_list,\"Recall\":sensitivity_list,\"F1\":f_score_list})\n",
    "    display(table)\n",
    "    \n",
    "def on_extract_image_data_clicked(x):\n",
    "    block_size = block_size_input.value\n",
    "    imageClassifier.create_data_set(block_size)\n",
    "\n",
    "def on_train_model_clicked(x):\n",
    "    use_custom=use_custom_input.value\n",
    "    imageClassifier.train_model(use_custom)\n",
    "\n",
    "def on_find_best_random_clicked(x):\n",
    "    imageClassifier.find_RandomizedSearchCV_best_params()\n",
    "\n",
    "def on_find_best_grid_clicked(x):\n",
    "    imageClassifier.find_GridSearchCV_best_params()\n",
    "    \n",
    "def on_model_find_fundus_clicked(x):\n",
    "    imageClassifier.find_fundus()\n",
    "    \n",
    "def on_final_process_finished_clicked(x):\n",
    "    path = finished_path_input.value\n",
    "    mask_imageReader = ImageReader()\n",
    "    mask_imageReader.upload_many_images(path)\n",
    "    \n",
    "    orig_imageReader = ImageReader()\n",
    "    orig_imageReader.upload_many_images(\"img/\")\n",
    "    for i,(mask,orig) in enumerate(zip(mask_imageReader.get_images_array(),orig_imageReader.get_images_array())):\n",
    "        img=apply_pic_on_pic(orig,mask)\n",
    "        display_picture(img,\"img/image-results/model-applied-\"+str(i)+\".jpg\")\n",
    "    \n",
    "    accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list = calculate_statistics(mask_imageReader.get_images_array(), mask_imageReader.get_expected_array(), filename=\"models\")\n",
    "    table = pd.DataFrame({\"Accuracy\": accuracy_list,\"Sensitivity\": sensitivity_list,\"Specificity\": specificity_list, \"Geometric mean\":g_mean_list,\"Precision\": precision_list,\"Recall\":sensitivity_list,\"F1\":f_score_list})\n",
    "    display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for the buttons and other input options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "vertical_box_layout = Layout(display='flex',\n",
    "                    flex_flow='column',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "single_image_label= widgets.Label(value = 'Choose single image to process...')\n",
    "files = [f for f in listdir(\"img/\") if isfile(join(\"img/\", f))]\n",
    "\n",
    "filename_input = widgets.Dropdown(\n",
    "    options=files,\n",
    "    value='01_h.jpg',\n",
    "    description='filename',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "upload_button = widgets.Button(description = \"Upload image\")\n",
    "upload_button.style.button_color = 'lightpink'\n",
    "upload_button.on_click(functools.partial(on_upload_clicked))\n",
    "\n",
    "single_image_box = Box([single_image_label,filename_input,upload_button], layout = vertical_box_layout)\n",
    "\n",
    "many_images_label= widgets.Label(value = '...or process the full directory')\n",
    "filepath_input = widgets.Text(layout=Layout(width='350px'),description='directory',value='img/')\n",
    "upload_many_button = widgets.Button(description = \"Update images\")\n",
    "upload_many_button.style.button_color = 'lightpink'\n",
    "upload_many_button.on_click(functools.partial(on_upload_many_clicked))\n",
    "\n",
    "\n",
    "many_images_box = Box([many_images_label,filepath_input,upload_many_button], layout = vertical_box_layout)\n",
    "\n",
    "items = [single_image_box,many_images_box]\n",
    "\n",
    "choose_image_box = Box(children=items, layout=horizontal_box_layout)\n",
    "\n",
    "find_fundus_button = widgets.Button(description=\"Find fundus\")\n",
    "find_fundus_button.style.button_color = 'lightpink'\n",
    "find_fundus_button.on_click(functools.partial(on_find_fundus_clicked))\n",
    "\n",
    "check_stats_button = widgets.Button(description=\"Check stats!\")\n",
    "check_stats_button.style.button_color = 'lightpink'\n",
    "check_stats_button.on_click(functools.partial(on_check_stats_clicked, True))\n",
    "\n",
    "sizes = [4,5,15,25,64]\n",
    "warning_label= widgets.Label(value = 'Choose image to train your model in the upper single image choosing panel')\n",
    "block_size_label= widgets.Label(value = 'Choose to what size blocks split images')\n",
    "block_size_input = widgets.Dropdown(\n",
    "    options=sizes,\n",
    "    value=4,\n",
    "    description='blocks size',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "extract_data_button = widgets.Button(description=\"Extract image data\")\n",
    "extract_data_button.style.button_color = 'lightpink'\n",
    "extract_data_button.on_click(functools.partial(on_extract_image_data_clicked))\n",
    "\n",
    "prepare_data_box = Box([warning_label,block_size_label,block_size_input,extract_data_button], layout = vertical_box_layout)\n",
    "\n",
    "warning_random_label= widgets.Label(value = 'Warning! Finding best random parameters may take hours')\n",
    "find_best_random_button = widgets.Button(description=\"Find best random params\")\n",
    "find_best_random_button.style.button_color = 'lightpink'\n",
    "find_best_random_button.on_click(functools.partial(on_find_best_random_clicked))\n",
    "\n",
    "find_params_left = Box([warning_random_label,find_best_random_button],layout=vertical_box_layout)\n",
    "\n",
    "warning_grid_label= widgets.Label(value = 'Faster than random but still slow:')\n",
    "find_best_grid_button = widgets.Button(description=\"Find best grid params\")\n",
    "find_best_grid_button.style.button_color = 'lightpink'\n",
    "find_best_grid_button.on_click(functools.partial(on_find_best_grid_clicked))\n",
    "\n",
    "find_params_right = Box([warning_grid_label,find_best_grid_button],layout=vertical_box_layout)\n",
    "\n",
    "find_best_params_box = Box([find_params_left,find_params_right], layout = horizontal_box_layout)\n",
    "\n",
    "\n",
    "set_model_params_label = widgets.Label(value='Enter model params or leave default')\n",
    "\n",
    "bootstrap_input = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Bootstrap',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "n_estimators_input = widgets.IntSlider(\n",
    "    value=800,\n",
    "    min=0,\n",
    "    max=1000,\n",
    "    step=100,\n",
    "    description='Number of trees',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "criterion_input = widgets.Dropdown(\n",
    "    options=['gini', 'entropy'],\n",
    "    value='gini',\n",
    "    description='Criterion',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "max_depth_input = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=10,\n",
    "    description='Max depth',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "max_features_input = widgets.Dropdown(\n",
    "    options=['auto', 'sqrt','2','3'],\n",
    "    value='3',\n",
    "    description='Max features',\n",
    ")\n",
    "min_samples_leaf_input = widgets.Dropdown(\n",
    "    options=['1', '2','4'],\n",
    "    value='4',\n",
    "    description='Min samples leaf',\n",
    ")\n",
    "\n",
    "min_samples_split_input = widgets.Dropdown(\n",
    "    options=['5','10','12','15'],\n",
    "    value='12',\n",
    "    description='Min samples split',\n",
    ")\n",
    "\n",
    "use_custom_input = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Use this params',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "train_model_button = widgets.Button(description=\"Train best model!\")\n",
    "train_model_button.style.button_color = 'lightpink'\n",
    "train_model_button.on_click(functools.partial(on_train_model_clicked))\n",
    "\n",
    "left_params_box = Box([bootstrap_input,n_estimators_input,criterion_input,max_depth_input],layout = vertical_box_layout)\n",
    "right_params_box = Box([max_features_input,min_samples_leaf_input,min_samples_split_input,use_custom_input],layout = vertical_box_layout)\n",
    "params_box = Box([left_params_box,right_params_box],layout = horizontal_box_layout)\n",
    "set_params_box = Box([set_model_params_label,params_box,train_model_button],layout = vertical_box_layout)\n",
    "\n",
    "update_button = widgets.Button(description = \"Update image\")\n",
    "update_button.style.button_color = 'lightpink'\n",
    "update_button.on_click(functools.partial(on_update_clicked))\n",
    "\n",
    "model_find_fundus=widgets.Button(description=\"Find fundus!\")\n",
    "model_find_fundus.style.button_color = 'lightpink'\n",
    "model_find_fundus.on_click(functools.partial(on_model_find_fundus_clicked))\n",
    "model_find_funudus_box = Box([single_image_label,filename_input,update_button,model_find_fundus], layout = vertical_box_layout)\n",
    "\n",
    "check_model_stats_button = widgets.Button(description=\"Check model stats!\")\n",
    "check_model_stats_button.style.button_color = 'lightpink'\n",
    "check_model_stats_button.on_click(functools.partial(on_check_stats_clicked, False))\n",
    "\n",
    "warning_process_finished_label= widgets.Label(value = 'Enter models results mask path for applying and stats at the end:')\n",
    "finished_path_input = widgets.Text(layout=Layout(width='350px'),description='directory',value='img/models-masks')\n",
    "\n",
    "final_process_finished_button = widgets.Button(description=\"Apply and stats!\")\n",
    "final_process_finished_button.style.button_color = 'lightpink'\n",
    "final_process_finished_button.on_click(functools.partial(on_final_process_finished_clicked))\n",
    "\n",
    "final_masks_box = Box([warning_process_finished_label,finished_path_input,final_process_finished_button],layout=vertical_box_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
