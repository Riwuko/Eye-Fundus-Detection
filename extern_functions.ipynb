{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External functions for Fundus of the Eye detecting\n",
    "Makes the main application clear for user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import functools\n",
    "from IPython.display import Markdown, clear_output, display, HTML\n",
    "from ipywidgets import widgets, Layout,Label, HBox, VBox, Box\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from skimage.filters import gaussian, threshold_li, sato\n",
    "from skimage import img_as_float\n",
    "from skimage.color import rgb2hsv,rgb2gray,hsv2rgb\n",
    "import skimage.morphology as mp\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, make_scorer, recall_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions for displaying and loading pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_picture(image, title=None):\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    sub = fig.add_subplot(111)\n",
    "    if title is not None:\n",
    "        sub.set_title(title)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image) \n",
    "\n",
    "def display_results(image_array,titles_array):\n",
    "    count = len(image_array)\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=count, figsize=(30,6))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        plt.sca(ax)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image_array[i])\n",
    "        plt.title(titles_array[i])\n",
    "\n",
    "    plt.suptitle(\"Process of finding eye's fundus\")\n",
    "    plt.savefig('img/image-results/test.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "def display_statistics_plot(expect,mask,tpr,fpr,roc_auc):\n",
    "    fig = plt.figure(figsize=(20,6))\n",
    "    title = \"Classifications metrics\"\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    original = fig.add_subplot(131)\n",
    "    original.set_title('Expert mask')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(expect)\n",
    "\n",
    "    roc_curve = fig.add_subplot(132)\n",
    "    roc_curve.set_title('Receiver Operating Characteristic')\n",
    "    roc_curve.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    roc_curve.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    xlim=[0.0, 1.0]\n",
    "    ylim=[0.0, 1.05]\n",
    "    roc_curve.set_xlim(xlim)\n",
    "    roc_curve.set_ylim(ylim)\n",
    "    roc_curve.set_xlabel('False Positive Rate')\n",
    "    roc_curve.set_ylabel('True Positive Rate')\n",
    "\n",
    "    actual = fig.add_subplot(133)\n",
    "    actual.set_title('Obtained mask')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(mask)\n",
    "    \n",
    "    stats = fig.add_subplot(211)\n",
    "    stats.axis('tight')\n",
    "    stats.axis('off')\n",
    "    labels=list(table.keys())\n",
    "    text=list(table.values())\n",
    "    stats.table(cellText=text,colLabels=labels,loc='center')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def display_label_distribution(y_train,y_test):\n",
    "    classes_number = 2\n",
    "    fig, ax = plt.subplots()\n",
    "    training_counts = [None] * classes_number \n",
    "    testing_counts = [None] * classes_number\n",
    "    for i in range(classes_number):\n",
    "        training_counts[i] = len(y_train[y_train == i])\n",
    "        testing_counts[i] = len(y_test[y_test == i])\n",
    "\n",
    "    train_bar = plt.bar(np.arange(classes_number)-0.2, training_counts, align='center', color = 'pink', alpha=0.75, width = 0.41, label='Training')\n",
    "    test_bar = plt.bar(np.arange(classes_number)+0.2, testing_counts, align='center', color = 'teal', alpha=0.75, width = 0.41, label = 'Testing')\n",
    "   \n",
    "    ax.set_xlabel('Labels')\n",
    "    x_ticks_labels = ['Background','Vessel']\n",
    "    ax.set_xticks((0,1))\n",
    "    ax.set_xticklabels(x_ticks_labels,rotation='horizontal', fontsize=14)\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.title('Label distribution in the training and test set')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), handles=[train_bar, test_bar], loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def load_image(path,file):\n",
    "    if('.jpg' in file or '.png' or '.tif' in file):\n",
    "        full_file = path+file\n",
    "        img = cv2.imread(full_file)\n",
    "        return img\n",
    "\n",
    "def apply_pic_on_pic(img1,img2):\n",
    "    img2=img_as_float(rgb2gray(img2))\n",
    "    h = img1.shape[0]\n",
    "    w = img2.shape[1]\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            img1[y, x] = 255 if img2[y, x] == 1 else img1[y,x]\n",
    "\n",
    "    return img1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for buttons \"on-click\"\n",
    "Reacting for using application's buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_update_clicked(x, img_array, expected_array):\n",
    "    clear_output()\n",
    "    display(choose_image_box)\n",
    "    \n",
    "    path = 'img/'\n",
    "    expected_path = 'img/expected/'\n",
    "    filepath = filename_input.value\n",
    "    \n",
    "    img_array.clear()\n",
    "    img = cv2.imread(path+filepath)\n",
    "    img_array.append(img)\n",
    "    \n",
    "    expected = cv2.imread(expected_path+filepath)\n",
    "    expected_array.append(expected)\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    sub = fig.add_subplot(111)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "def on_update_many_clicked(x, img_array, expected_array):\n",
    "    clear_output()\n",
    "    display(choose_image_box)\n",
    "    \n",
    "    path = filepath_input.value\n",
    "    expected_path = path+'expected/'\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for i,file in enumerate(files):\n",
    "            img = load_image(path,file)\n",
    "            img_array.append(img)\n",
    "                \n",
    "            expected_img = load_image(expected_path,file)\n",
    "            expected_array.append(expected_img)\n",
    "    print(f'Updated {i+1} files!')\n",
    "\n",
    "\n",
    "def on_find_fundus_clicked(x, images_array, mask):\n",
    "    if len(images_array)==0:\n",
    "        display (Markdown('<span style=\"color: #ff0000\">Upload image first!</span>'))\n",
    "        return\n",
    "    \n",
    "    for img in images_array:\n",
    "        img_orig = img.copy()\n",
    "        img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        initial = initial_processing(img)\n",
    "        \n",
    "        edges = edge_detecting(initial,mask)\n",
    "        detections_mask = vessels_mask(edges)\n",
    "        final_fundus = fundus_final_processing(detections_mask)\n",
    "        \n",
    "        final_fundus = cv2.cvtColor(final_fundus, cv2.COLOR_BGR2RGB)\n",
    "        result_masks.append(final_fundus)\n",
    "        \n",
    "        detection_on_orygin = apply_pic_on_pic(img_orig.copy(),final_fundus)\n",
    "        \n",
    "        image_progress=[img_orig,initial,final_fundus,detection_on_orygin]\n",
    "        titles=['Original picture','Initial processing','Fundus mask','Applied on original']\n",
    "    \n",
    "        display_results(image_progress, titles)\n",
    "   \n",
    " \n",
    "def on_check_stats_clicked(x,result_masks, expected_array):\n",
    "    accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list = calculate_statistics(result_masks, expected_array)\n",
    "    \n",
    "    print(\"Accuracy is inappropriate for imbalanced classification because a high accuracy is achievable by a no skill model that only predicts the majority class.\")\n",
    "    \n",
    "    print(\"Metrics that may be useful for imbalanced classification because they focus on one class are: sensitivity-specificity and precision-recall.\")\n",
    "    print(\"Sensitivity (recall) is  how well the positive class was predicted.\")\n",
    "    print('Specificity is  how well the negative class was predicted.')\n",
    "    print('Sensitivity and specificity can be combined into a single score that balances both concerns, called the geometric mean.')\n",
    "    \n",
    "    print('Precision summarizes the fraction of examples assigned the positive class that belong to the positive class.')\n",
    "    print(\"Precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score.\")\n",
    "    \n",
    "    table = pd.DataFrame({\"Accuracy\": accuracy_list,\"Sensitivity\": sensitivity_list,\"Specificity\": specificity_list, \"Geometric mean\":g_mean_list,\"Precision\": precision_list,\"Recall\":sensitivity_list,\"F1\":f_score_list})\n",
    "    display(table)\n",
    "    \n",
    "    \n",
    "\n",
    "def on_extract_image_data_clicked(x,images_array,expected_array):\n",
    "    block_size = block_size_input.value\n",
    "    img = images_array[0]\n",
    "    expected = expected_array[0]\n",
    "\n",
    "    img = initial_processing(img)\n",
    "    parts,decisions = split_image(img,expected,block_size)\n",
    "\n",
    "    data=[]\n",
    "    for part,decision in zip(parts,decisions):\n",
    "        data.append(image_features_extract(part,decision))\n",
    "    data_set = pd.DataFrame(data)\n",
    "    print('Image based data frame:')\n",
    "    display(data_set.head())\n",
    "    data_set.to_csv('data/model_data.csv')\n",
    "    \n",
    "def on_train_model_clicked(x):\n",
    "    bootstrap,n_estimators,criterion,max_depth,max_features,min_samples_leaf,min_samples_split = get_input_model_params()\n",
    "    train_model(bootstrap,n_estimators,criterion,max_depth,max_features,min_samples_leaf,min_samples_split)\n",
    "    \n",
    "def on_find_best_random_clicked(x):\n",
    "    find_RandomizedSearchCV_best_params()\n",
    "\n",
    "def on_find_best_grid_clicked(x):\n",
    "    find_GridSearchCV_best_params()\n",
    "    \n",
    "    \n",
    "def get_input_model_params():\n",
    "    bootstrap=bootstrap_input.value\n",
    "    n_estimators=n_estimators_input.value\n",
    "    criterion=criterion_input.value\n",
    "    max_depth=max_depth_input.value\n",
    "    max_features=max_features_input.value\n",
    "    min_samples_leaf=min_samples_leaf_input.value\n",
    "    min_samples_split=min_samples_split_input.value\n",
    "    return bootstrap,n_estimators,criterion,max_depth,max_features,min_samples_leaf,min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing\n",
    "Functions for calculating the statistics and machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(bootstrap,n_estimators,criterion,max_depth,max_features,min_samples_leaf,min_samples_split):\n",
    "    X,y = get_X_y()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y)\n",
    "    display_label_distribution(y_train,y_test)\n",
    "    \n",
    "    \n",
    "def get_X_y():\n",
    "    data_set = pd.read_csv('data/model_data.csv')\n",
    "    data_set=data_set.drop(\"Unnamed: 0\",axis=1)\n",
    "    \n",
    "    X = data_set.iloc[:, :-1].values\n",
    "    y = data_set.iloc[:, -1].values\n",
    "    \n",
    "    rus=RandomUnderSampler()\n",
    "    X, y = rus.fit_resample(X, y)\n",
    "    \n",
    "    return X,y\n",
    "    \n",
    "\n",
    "def find_RandomizedSearchCV_best_params():\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]   # Minimum number of samples required to split a node\n",
    "    min_samples_leaf = [1, 2, 4]     # Minimum number of samples required at each leaf node\n",
    "    bootstrap = [True, False]        # Method of selecting samples for training each tree\n",
    "    \n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap }\n",
    "    \n",
    "    print(\"Using the random grid to search for best parameters\")\n",
    "    print(\"Random Grid options: \\n\")\n",
    "    pprint(random_grid)\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # n_iter controls the number of different combinations to try\n",
    "    # cv is the number of folds to use for cross validation\n",
    "    \n",
    "    X, y = get_X_y()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y)\n",
    "    \n",
    "    rf_random.fit(X_train, y_train)\n",
    "    best_random = rf_random.best_estimator_\n",
    "    \n",
    "    print(\"\\nRandom best params:\")\n",
    "    pprint(rf_random.best_params_)\n",
    "    \n",
    "    print(\"\\nRandom best estimator:\")\n",
    "    pprint(best_random)\n",
    "\n",
    "def find_GridSearchCV_best_params():\n",
    "    param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [80, 90, 100, 110],\n",
    "        'max_features': [2, 3],\n",
    "        'min_samples_leaf': [3, 4, 5],\n",
    "        'min_samples_split': [8, 10, 12],\n",
    "        'n_estimators': [100, 200, 300, 1000]\n",
    "    }  #grid parameters based on RandomizedSearchCV best params\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "    X, y = get_X_y()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,stratify=y)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_grid = rf_random.best_estimator_\n",
    "    \n",
    "    print(\"\\nGrid best params:\")\n",
    "    pprint(rf_random.best_params_)\n",
    "    \n",
    "    print(\"\\nGrid best estimator:\")\n",
    "    pprint(best_random)\n",
    "\n",
    "def calculate_statistics(result_mask, expected_array):\n",
    "    accuracy_list=[]\n",
    "    sensitivity_list=[]\n",
    "    precision_list=[]\n",
    "    specificity_list=[]\n",
    "    fpr_list=[]\n",
    "    f_score_list=[]\n",
    "    g_mean_list=[]\n",
    "    \n",
    "    for mask, expect in zip(result_masks, expected_array): \n",
    "        mask_copy, expect_copy = binarize_images(mask.copy(),expect.copy())\n",
    "        mask_array = mask_copy.flatten()\n",
    "        expect_array = expect_copy.flatten()\n",
    "        \n",
    "        true_negative, false_positive, false_negative, true_positive = confusion_matrix(mask_array, expect_array, labels=[0,1]).ravel()\n",
    "        fpr, tpr, _ = roc_curve(expect_array, mask_array)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        accuracy =  (true_positive + true_negative) / (true_positive+true_negative+false_positive+false_negative)#trafnosc\n",
    "        sensitivity =  true_positive / (true_positive + false_negative)#czulosc : tp / (tp + fn)\n",
    "        precision = true_positive / (true_positive + false_positive) # tp / tp + fp\n",
    "        specificity = true_negative / (true_negative + false_positive) #swoistosc: tn / (tn + fp)\n",
    "        f_score = 2 * precision * sensitivity /  ( precision + sensitivity)\n",
    "        g_mean = np.sqrt(sensitivity*specificity)\n",
    "        \n",
    "        accuracy_list.append(accuracy)\n",
    "        sensitivity_list.append(sensitivity)\n",
    "        precision_list.append(precision)\n",
    "        specificity_list.append(specificity)\n",
    "        f_score_list.append(f_score) \n",
    "        g_mean_list.append(g_mean)\n",
    "        \n",
    "        display_statistics_plot(expect,mask,tpr,fpr,roc_auc)\n",
    "        \n",
    "    return accuracy_list,sensitivity_list,precision_list,specificity_list,f_score_list,g_mean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual image processing\n",
    "Functions for manual processing of the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_processing(img):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl,a,b))\n",
    "    clahed_image = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "    clahed_image[:, :, 0] = 0\n",
    "    clahed_image[:, :, 2] = 0\n",
    "    img=img_as_float(rgb2gray(clahed_image))\n",
    "    img=gaussian(img,sigma=3) \n",
    "    img=img**0.2\n",
    "    img=sato(img) \n",
    "    return img\n",
    "\n",
    "def edge_detecting(img, mask):\n",
    "    img = (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "    img=mp.dilation(img,selem=mp.disk(6))\n",
    "    img=gaussian(img,sigma=3) \n",
    "    img=mp.closing(img, selem=mp.disk(8))\n",
    "    img=mp.erosion(img,selem=mp.disk(2))\n",
    "\n",
    "    thresh = threshold_li(img, tolerance=0.0005)\n",
    "    img = img > thresh\n",
    "\n",
    "    mask=img_as_float(rgb2gray(mask))\n",
    "    mask=mp.erosion(mask, selem=mp.disk(5))\n",
    "    img=img*mask\n",
    "\n",
    "    return img\n",
    "\n",
    "def vessels_mask(img):\n",
    "    detection = np.zeros((img.shape[0], img.shape[1], 3), np.uint8)\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            if cv2.countNonZero(img[y, x]) > 0:\n",
    "                detection[y, x] = np.array([255, 255, 255], np.uint8)\n",
    "  \n",
    "    return detection\n",
    "\n",
    "def fundus_final_processing(img):\n",
    "    img = np.array(img)\n",
    "    img = 255*(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 5).astype('uint8')\n",
    "\n",
    "    img=mp.erosion(img,selem=mp.disk(1))\n",
    "    img=mp.closing(img, selem=mp.disk(15))\n",
    "    \n",
    "    img = cv2.threshold(img, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    return img\n",
    "\n",
    "def binarize_images(mask,expect,value=[1,1,1],thresh=0):\n",
    "    black=[0,0,0]\n",
    "    h = expect.shape[0]\n",
    "    w = expect.shape[1]\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            expect_vessel = expect[y,x]\n",
    "            detect_vessel = mask[y,x]\n",
    "            if np.amax(expect_vessel) > thresh:\n",
    "                expect[y,x]=value\n",
    "                if np.amax(detect_vessel) >thresh:\n",
    "                    mask[y,x]=value\n",
    "                else:\n",
    "                    mask[y,x]=black\n",
    "            else:\n",
    "                expect[y,x]=black\n",
    "                if np.amax(detect_vessel) > thresh:\n",
    "                    mask[y,x]=value\n",
    "                else:\n",
    "                    mask[y,x]=black\n",
    "    return mask,expect\n",
    "\n",
    "def split_image(img,expect, block_size):\n",
    "    windows=[]\n",
    "    decisions = []\n",
    "    exp_windows=[]\n",
    "#     expect,_ = binarize_images(expect,expect,[255,255,255],20)\n",
    "    for r in range(0,img.shape[0] - block_size, block_size):\n",
    "        for c in range(0,img.shape[0] - block_size, block_size):\n",
    "            window = img[r:r+block_size,c:c+block_size]\n",
    "            exp_window = expect[r:r+block_size,c:c+block_size]\n",
    "            center = np.amax(exp_window[exp_window.shape[0]//2,exp_window.shape[1]//2])\n",
    "            if center>50:\n",
    "                center=1\n",
    "            else:\n",
    "                center=0\n",
    "            exp_windows.append(exp_window)\n",
    "            decisions.append(center)\n",
    "            windows.append(window)\n",
    "                \n",
    "    return windows,decisions\n",
    "    \n",
    "            \n",
    "def image_features_extract(img, decision):\n",
    "    data={}\n",
    "    data['variance'] = np.var(img)\n",
    "    img=img_as_float(rgb2gray(img))\n",
    "    moments = cv2.moments(img)\n",
    "    data={**data,**moments}\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    for i,hu in enumerate(hu_moments):\n",
    "        name = \"hu\"+str(i)\n",
    "        data[name]=hu[0]\n",
    "    data['decision']=decision\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for the buttons and other input options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_array=[]\n",
    "image_mask = load_image('img/mask/','01_h_mask.tif')\n",
    "result_masks = []\n",
    "expected_array=[]\n",
    "\n",
    "horizontal_box_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "vertical_box_layout = Layout(display='flex',\n",
    "                    flex_flow='column',\n",
    "                    align_items='stretch',\n",
    "                    width='100%')\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "single_image_label= widgets.Label(value = 'Choose single image to process...')\n",
    "files = [f for f in listdir(\"img/\") if isfile(join(\"img/\", f))]\n",
    "\n",
    "filename_input = widgets.Dropdown(\n",
    "    options=files,\n",
    "    value='01_h.jpg',\n",
    "    description='filename',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "update_button = widgets.Button(description = \"Update image\")\n",
    "update_button.style.button_color = 'lightpink'\n",
    "update_button.on_click(functools.partial(on_update_clicked, img_array = images_array, expected_array = expected_array))\n",
    "\n",
    "single_image_box = Box([single_image_label,filename_input,update_button], layout = vertical_box_layout)\n",
    "\n",
    "many_images_label= widgets.Label(value = '...or process the full directory')\n",
    "filepath_input = widgets.Text(layout=Layout(width='350px'),description='directory',value='img/')\n",
    "update_many_button = widgets.Button(description = \"Update images\")\n",
    "update_many_button.style.button_color = 'lightpink'\n",
    "update_many_button.on_click(functools.partial(on_update_many_clicked,img_array = images_array, expected_array = expected_array))\n",
    "\n",
    "\n",
    "many_images_box = Box([many_images_label,filepath_input,update_many_button], layout = vertical_box_layout)\n",
    "\n",
    "items = [single_image_box,many_images_box]\n",
    "\n",
    "choose_image_box = Box(children=items, layout=horizontal_box_layout)\n",
    "\n",
    "find_fundus_button = widgets.Button(description=\"Find fundus\")\n",
    "find_fundus_button.style.button_color = 'lightpink'\n",
    "find_fundus_button.on_click(functools.partial(on_find_fundus_clicked,images_array = images_array,mask = image_mask))\n",
    "\n",
    "check_stats_button = widgets.Button(description=\"Check stats!\")\n",
    "check_stats_button.style.button_color = 'lightpink'\n",
    "check_stats_button.on_click(functools.partial(on_check_stats_clicked,result_masks = result_masks, expected_array = expected_array))\n",
    "\n",
    "sizes = [4,5,7]\n",
    "\n",
    "warning_label= widgets.Label(value = 'Choose image to train your model in the upper single image choosing panel')\n",
    "block_size_label= widgets.Label(value = 'Choose to what size blocks split images')\n",
    "block_size_input = widgets.Dropdown(\n",
    "    options=sizes,\n",
    "    value=4,\n",
    "    description='blocks size',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "extract_data_button = widgets.Button(description=\"Extract image data\")\n",
    "extract_data_button.style.button_color = 'lightpink'\n",
    "extract_data_button.on_click(functools.partial(on_extract_image_data_clicked, images_array=images_array, expected_array = expected_array))\n",
    "\n",
    "prepare_data_box = Box([warning_label,block_size_label,block_size_input,extract_data_button], layout = vertical_box_layout)\n",
    "\n",
    "warning_random_label= widgets.Label(value = 'Warning! Finding best random parameters may take a few hours')\n",
    "find_best_random_button = widgets.Button(description=\"Find best random params\")\n",
    "find_best_random_button.style.button_color = 'lightpink'\n",
    "find_best_random_button.on_click(functools.partial(on_find_best_random_clicked))\n",
    "\n",
    "warning_grid_label= widgets.Label(value = 'Faster than random but still slow:')\n",
    "find_best_grid_button = widgets.Button(description=\"Find best grid params\")\n",
    "find_best_grid_button.style.button_color = 'lightpink'\n",
    "find_best_grid_button.on_click(functools.partial(on_find_best_grid_clicked))\n",
    "\n",
    "find_best_params_box = Box([warning_random_label,find_best_random_button,warning_grid_label,find_best_grid_button], layout = vertical_box_layout)\n",
    "\n",
    "\n",
    "set_model_params_label = widgets.Label(value='Enter model params or leave default')\n",
    "\n",
    "bootstrap_input = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Bootstrap',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "n_estimators_input = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=1000,\n",
    "    step=100,\n",
    "    description='Number of trees',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "criterion_input = widgets.Dropdown(\n",
    "    options=['gini', 'entropy'],\n",
    "    value='gini',\n",
    "    description='Criterion',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "max_depth_input = widgets.IntSlider(\n",
    "    value=8,\n",
    "    min=10,\n",
    "    max=100,\n",
    "    step=10,\n",
    "    description='Max depth',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "max_features_input = widgets.Dropdown(\n",
    "    options=['auto', 'sqrt'],\n",
    "    value='sqrt',\n",
    "    description='Max features',\n",
    ")\n",
    "min_samples_leaf_input = widgets.Dropdown(\n",
    "    options=['1', '2','4'],\n",
    "    value='1',\n",
    "    description='Min samples leaf',\n",
    ")\n",
    "\n",
    "min_samples_split_input = widgets.Dropdown(\n",
    "    options=['2', '5','10'],\n",
    "    value='2',\n",
    "    description='Min samples leaf',\n",
    ")\n",
    "\n",
    "train_model_button = widgets.Button(description=\"Train best model!\")\n",
    "train_model_button.style.button_color = 'lightpink'\n",
    "train_model_button.on_click(functools.partial(on_train_model_clicked))\n",
    "\n",
    "left_params_box = Box([bootstrap_input,n_estimators_input,criterion_input,max_depth_input],layout = vertical_box_layout)\n",
    "right_params_box = Box([max_features_input,min_samples_leaf_input,min_samples_split_input],layout = vertical_box_layout)\n",
    "params_box = Box([left_params_box,right_params_box],layout = horizontal_box_layout)\n",
    "set_params_box = Box([set_model_params_label,params_box,train_model_button],layout = vertical_box_layout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
